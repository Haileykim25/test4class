{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haileykim25/test4class/blob/main/chapter05_fundamentals_of_ml_i%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQWda75WTAyt"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIvqjeEETAyv"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSAMHL4nTAyv"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAzQ7NGoTAyw"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DJB6J-DTAyw"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nFrYtXrTAyw"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqAfEnwwTAyw"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBJDaJw0TAyw"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha1mMoGpTAyw",
        "outputId": "81d6a705-0201-41c6-b46b-548e1cbd136b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.random((len(train_images), 784))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKcMaSifbCHX",
        "outputId": "99f7286b-2761-468c-917e-a8f314d4a2f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52630259, 0.31973751, 0.0366051 , ..., 0.71451   , 0.7944738 ,\n",
              "        0.78142901],\n",
              "       [0.43264602, 0.51626212, 0.68030551, ..., 0.85042851, 0.17103558,\n",
              "        0.63165274],\n",
              "       [0.7870852 , 0.05241646, 0.01123677, ..., 0.1396995 , 0.90006568,\n",
              "        0.54264353],\n",
              "       ...,\n",
              "       [0.79801469, 0.38792522, 0.12157475, ..., 0.1013637 , 0.19499918,\n",
              "        0.58971542],\n",
              "       [0.74113869, 0.39510314, 0.15686025, ..., 0.21875646, 0.98154978,\n",
              "        0.79801513],\n",
              "       [0.05144337, 0.33513223, 0.69442513, ..., 0.84585984, 0.97423932,\n",
              "        0.27648417]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((len(train_images), 784))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG60D-bdbEhK",
        "outputId": "dd350200-672c-4b37-93ba-9a6a74fd752e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18xFOmGUTAyx"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCgp_Bq0TAyy",
        "outputId": "d1be9247-a62b-4d8f-a0a5-5919780aac86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.7042 - loss: 1.0148 - val_accuracy: 0.9120 - val_loss: 0.2855\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.9118 - loss: 0.2751 - val_accuracy: 0.9116 - val_loss: 0.2838\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9469 - loss: 0.1706 - val_accuracy: 0.9470 - val_loss: 0.1771\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9623 - loss: 0.1228 - val_accuracy: 0.9496 - val_loss: 0.1680\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9730 - loss: 0.0850 - val_accuracy: 0.9647 - val_loss: 0.1194\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9812 - loss: 0.0600 - val_accuracy: 0.9645 - val_loss: 0.1330\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9838 - loss: 0.0488 - val_accuracy: 0.9693 - val_loss: 0.1172\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9913 - loss: 0.0296 - val_accuracy: 0.9642 - val_loss: 0.1335\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9930 - loss: 0.0233 - val_accuracy: 0.9700 - val_loss: 0.1180\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9956 - loss: 0.0152 - val_accuracy: 0.9717 - val_loss: 0.1175\n",
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8588 - loss: 0.4881 - val_accuracy: 0.9494 - val_loss: 0.1726\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9620 - loss: 0.1344 - val_accuracy: 0.9682 - val_loss: 0.1055\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9751 - loss: 0.0854 - val_accuracy: 0.9727 - val_loss: 0.0911\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9839 - loss: 0.0562 - val_accuracy: 0.9735 - val_loss: 0.0900\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9873 - loss: 0.0428 - val_accuracy: 0.9781 - val_loss: 0.0772\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9906 - loss: 0.0318 - val_accuracy: 0.9770 - val_loss: 0.0793\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9932 - loss: 0.0243 - val_accuracy: 0.9731 - val_loss: 0.0875\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9953 - loss: 0.0180 - val_accuracy: 0.9783 - val_loss: 0.0791\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9969 - loss: 0.0133 - val_accuracy: 0.9787 - val_loss: 0.0768\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9975 - loss: 0.0108 - val_accuracy: 0.9802 - val_loss: 0.0773\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "#original data.."
      ],
      "metadata": {
        "id": "9hcfy7e7dy1w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdoFBY5rTAyy"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "rVgqTTX-TAyy",
        "outputId": "b346ba9a-f40d-40dd-ea92-17ed2afdde6b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history_ori' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3e85a87f9153>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_acc_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_acc_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_acc_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_ori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m plt.plot(epochs, val_acc_noise, \"b-\",\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history_ori' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "val_acc_ori = history_ori.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.plot(epochs, val_acc_ori, \"r--\",\n",
        "         label=\"Validation accuracy with original data\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM-QVAiuTAyy"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82TQ0lTZTAyy"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZVjzwByTAyz",
        "outputId": "cd914d11-b19b-489e-cb7c-cf35583fe140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1038 - loss: 2.3261 - val_accuracy: 0.1045 - val_loss: 2.3072\n",
            "Epoch 2/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.1199 - loss: 2.2978 - val_accuracy: 0.1039 - val_loss: 2.3144\n",
            "Epoch 3/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.1320 - loss: 2.2883 - val_accuracy: 0.1034 - val_loss: 2.3172\n",
            "Epoch 4/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.1413 - loss: 2.2769 - val_accuracy: 0.1018 - val_loss: 2.3218\n",
            "Epoch 5/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1583 - loss: 2.2601 - val_accuracy: 0.0988 - val_loss: 2.3388\n",
            "Epoch 6/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1736 - loss: 2.2374 - val_accuracy: 0.1045 - val_loss: 2.3416\n",
            "Epoch 7/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1838 - loss: 2.2129 - val_accuracy: 0.1016 - val_loss: 2.3516\n",
            "Epoch 8/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2044 - loss: 2.1869 - val_accuracy: 0.1028 - val_loss: 2.3709\n",
            "Epoch 9/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2206 - loss: 2.1573 - val_accuracy: 0.1015 - val_loss: 2.4026\n",
            "Epoch 10/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2366 - loss: 2.1192 - val_accuracy: 0.1017 - val_loss: 2.4243\n",
            "Epoch 11/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2531 - loss: 2.0845 - val_accuracy: 0.1044 - val_loss: 2.4451\n",
            "Epoch 12/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2727 - loss: 2.0441 - val_accuracy: 0.1046 - val_loss: 2.4574\n",
            "Epoch 13/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2919 - loss: 2.0055 - val_accuracy: 0.1053 - val_loss: 2.4977\n",
            "Epoch 14/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3068 - loss: 1.9707 - val_accuracy: 0.1062 - val_loss: 2.5229\n",
            "Epoch 15/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3246 - loss: 1.9288 - val_accuracy: 0.1005 - val_loss: 2.5600\n",
            "Epoch 16/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3412 - loss: 1.8851 - val_accuracy: 0.1033 - val_loss: 2.5918\n",
            "Epoch 17/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3609 - loss: 1.8457 - val_accuracy: 0.1042 - val_loss: 2.6376\n",
            "Epoch 18/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3781 - loss: 1.8031 - val_accuracy: 0.1073 - val_loss: 2.6524\n",
            "Epoch 19/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3869 - loss: 1.7684 - val_accuracy: 0.1037 - val_loss: 2.6951\n",
            "Epoch 20/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4038 - loss: 1.7235 - val_accuracy: 0.1047 - val_loss: 2.7456\n",
            "Epoch 21/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4173 - loss: 1.6876 - val_accuracy: 0.1090 - val_loss: 2.7981\n",
            "Epoch 22/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4387 - loss: 1.6417 - val_accuracy: 0.1008 - val_loss: 2.8290\n",
            "Epoch 23/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4521 - loss: 1.6052 - val_accuracy: 0.1047 - val_loss: 2.8909\n",
            "Epoch 24/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4590 - loss: 1.5777 - val_accuracy: 0.1058 - val_loss: 2.9216\n",
            "Epoch 25/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4755 - loss: 1.5405 - val_accuracy: 0.1041 - val_loss: 2.9890\n",
            "Epoch 26/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4887 - loss: 1.5047 - val_accuracy: 0.1014 - val_loss: 3.0083\n",
            "Epoch 27/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4965 - loss: 1.4731 - val_accuracy: 0.0998 - val_loss: 3.0686\n",
            "Epoch 28/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5142 - loss: 1.4365 - val_accuracy: 0.1038 - val_loss: 3.1073\n",
            "Epoch 29/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5273 - loss: 1.4055 - val_accuracy: 0.1047 - val_loss: 3.1747\n",
            "Epoch 30/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5362 - loss: 1.3768 - val_accuracy: 0.1050 - val_loss: 3.2385\n",
            "Epoch 31/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5464 - loss: 1.3467 - val_accuracy: 0.1042 - val_loss: 3.2838\n",
            "Epoch 32/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5639 - loss: 1.3070 - val_accuracy: 0.1005 - val_loss: 3.3163\n",
            "Epoch 33/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5701 - loss: 1.2826 - val_accuracy: 0.1022 - val_loss: 3.4011\n",
            "Epoch 34/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5816 - loss: 1.2536 - val_accuracy: 0.0999 - val_loss: 3.4336\n",
            "Epoch 35/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5933 - loss: 1.2238 - val_accuracy: 0.0978 - val_loss: 3.5157\n",
            "Epoch 36/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6032 - loss: 1.2000 - val_accuracy: 0.1016 - val_loss: 3.5605\n",
            "Epoch 37/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6137 - loss: 1.1706 - val_accuracy: 0.1052 - val_loss: 3.6242\n",
            "Epoch 38/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6193 - loss: 1.1416 - val_accuracy: 0.1017 - val_loss: 3.6793\n",
            "Epoch 39/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6314 - loss: 1.1163 - val_accuracy: 0.1041 - val_loss: 3.7415\n",
            "Epoch 40/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.6403 - loss: 1.0944 - val_accuracy: 0.0988 - val_loss: 3.7957\n",
            "Epoch 41/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6424 - loss: 1.0763 - val_accuracy: 0.0991 - val_loss: 3.8639\n",
            "Epoch 42/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6582 - loss: 1.0447 - val_accuracy: 0.1068 - val_loss: 3.9297\n",
            "Epoch 43/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6631 - loss: 1.0232 - val_accuracy: 0.1051 - val_loss: 3.9560\n",
            "Epoch 44/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6699 - loss: 1.0056 - val_accuracy: 0.1035 - val_loss: 4.0548\n",
            "Epoch 45/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6764 - loss: 0.9798 - val_accuracy: 0.1039 - val_loss: 4.0948\n",
            "Epoch 46/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6889 - loss: 0.9574 - val_accuracy: 0.1064 - val_loss: 4.1815\n",
            "Epoch 47/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6955 - loss: 0.9349 - val_accuracy: 0.1026 - val_loss: 4.2370\n",
            "Epoch 48/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7002 - loss: 0.9144 - val_accuracy: 0.1002 - val_loss: 4.3069\n",
            "Epoch 49/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7104 - loss: 0.9009 - val_accuracy: 0.1004 - val_loss: 4.3948\n",
            "Epoch 50/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7150 - loss: 0.8763 - val_accuracy: 0.1029 - val_loss: 4.4289\n",
            "Epoch 51/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7229 - loss: 0.8582 - val_accuracy: 0.1037 - val_loss: 4.4910\n",
            "Epoch 52/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7273 - loss: 0.8429 - val_accuracy: 0.1033 - val_loss: 4.5845\n",
            "Epoch 53/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.8302 - val_accuracy: 0.1032 - val_loss: 4.6338\n",
            "Epoch 54/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7403 - loss: 0.8068 - val_accuracy: 0.1035 - val_loss: 4.7116\n",
            "Epoch 55/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7469 - loss: 0.7884 - val_accuracy: 0.1034 - val_loss: 4.7567\n",
            "Epoch 56/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7550 - loss: 0.7675 - val_accuracy: 0.1032 - val_loss: 4.8290\n",
            "Epoch 57/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7553 - loss: 0.7590 - val_accuracy: 0.1036 - val_loss: 4.9054\n",
            "Epoch 58/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7667 - loss: 0.7328 - val_accuracy: 0.1019 - val_loss: 4.9886\n",
            "Epoch 59/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7654 - loss: 0.7276 - val_accuracy: 0.0991 - val_loss: 5.0645\n",
            "Epoch 60/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7728 - loss: 0.7114 - val_accuracy: 0.0997 - val_loss: 5.1132\n",
            "Epoch 61/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7782 - loss: 0.6968 - val_accuracy: 0.1010 - val_loss: 5.2070\n",
            "Epoch 62/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7827 - loss: 0.6845 - val_accuracy: 0.1028 - val_loss: 5.2371\n",
            "Epoch 63/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7893 - loss: 0.6680 - val_accuracy: 0.1063 - val_loss: 5.3353\n",
            "Epoch 64/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7942 - loss: 0.6476 - val_accuracy: 0.1030 - val_loss: 5.3833\n",
            "Epoch 65/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.6377 - val_accuracy: 0.0995 - val_loss: 5.4960\n",
            "Epoch 66/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7991 - loss: 0.6302 - val_accuracy: 0.1054 - val_loss: 5.5470\n",
            "Epoch 67/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.6123 - val_accuracy: 0.1003 - val_loss: 5.6016\n",
            "Epoch 68/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8110 - loss: 0.5955 - val_accuracy: 0.1045 - val_loss: 5.6953\n",
            "Epoch 69/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8154 - loss: 0.5875 - val_accuracy: 0.1035 - val_loss: 5.7844\n",
            "Epoch 70/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.5802 - val_accuracy: 0.1037 - val_loss: 5.8791\n",
            "Epoch 71/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8222 - loss: 0.5680 - val_accuracy: 0.0993 - val_loss: 5.9342\n",
            "Epoch 72/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8290 - loss: 0.5554 - val_accuracy: 0.1024 - val_loss: 5.9589\n",
            "Epoch 73/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8294 - loss: 0.5418 - val_accuracy: 0.1004 - val_loss: 6.0516\n",
            "Epoch 74/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8341 - loss: 0.5346 - val_accuracy: 0.1027 - val_loss: 6.1138\n",
            "Epoch 75/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8344 - loss: 0.5230 - val_accuracy: 0.1007 - val_loss: 6.1613\n",
            "Epoch 76/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8422 - loss: 0.5119 - val_accuracy: 0.1033 - val_loss: 6.2759\n",
            "Epoch 77/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8443 - loss: 0.5019 - val_accuracy: 0.1002 - val_loss: 6.3455\n",
            "Epoch 78/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8475 - loss: 0.4902 - val_accuracy: 0.1004 - val_loss: 6.4295\n",
            "Epoch 79/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8480 - loss: 0.4876 - val_accuracy: 0.1030 - val_loss: 6.5097\n",
            "Epoch 80/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8506 - loss: 0.4762 - val_accuracy: 0.1028 - val_loss: 6.5286\n",
            "Epoch 81/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8559 - loss: 0.4667 - val_accuracy: 0.1002 - val_loss: 6.6641\n",
            "Epoch 82/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8632 - loss: 0.4513 - val_accuracy: 0.0995 - val_loss: 6.7219\n",
            "Epoch 83/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8663 - loss: 0.4413 - val_accuracy: 0.1025 - val_loss: 6.7835\n",
            "Epoch 84/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.4351 - val_accuracy: 0.1026 - val_loss: 6.8774\n",
            "Epoch 85/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8669 - loss: 0.4314 - val_accuracy: 0.0988 - val_loss: 6.9589\n",
            "Epoch 86/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8740 - loss: 0.4159 - val_accuracy: 0.1002 - val_loss: 7.0349\n",
            "Epoch 87/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8737 - loss: 0.4099 - val_accuracy: 0.1023 - val_loss: 7.0962\n",
            "Epoch 88/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8794 - loss: 0.3999 - val_accuracy: 0.0978 - val_loss: 7.2104\n",
            "Epoch 89/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8785 - loss: 0.3955 - val_accuracy: 0.1026 - val_loss: 7.2644\n",
            "Epoch 90/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.3872 - val_accuracy: 0.0994 - val_loss: 7.3165\n",
            "Epoch 91/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8829 - loss: 0.3812 - val_accuracy: 0.0993 - val_loss: 7.3693\n",
            "Epoch 92/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8851 - loss: 0.3804 - val_accuracy: 0.1015 - val_loss: 7.4572\n",
            "Epoch 93/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8868 - loss: 0.3696 - val_accuracy: 0.0976 - val_loss: 7.5524\n",
            "Epoch 94/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8923 - loss: 0.3572 - val_accuracy: 0.1014 - val_loss: 7.6231\n",
            "Epoch 95/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8945 - loss: 0.3495 - val_accuracy: 0.1011 - val_loss: 7.7403\n",
            "Epoch 96/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8940 - loss: 0.3500 - val_accuracy: 0.0977 - val_loss: 7.7826\n",
            "Epoch 97/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8988 - loss: 0.3403 - val_accuracy: 0.1006 - val_loss: 7.8540\n",
            "Epoch 98/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8980 - loss: 0.3389 - val_accuracy: 0.1045 - val_loss: 7.9121\n",
            "Epoch 99/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9015 - loss: 0.3281 - val_accuracy: 0.1015 - val_loss: 8.0313\n",
            "Epoch 100/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9021 - loss: 0.3229 - val_accuracy: 0.0993 - val_loss: 8.0633\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAKu2IHCTAyz"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo2fj-JTTAyz"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPFBi79pTAyz"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGlHUW5PTAyz"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoJXsz4qTAyz"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIWkBodTAyz"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyiu8t5tTAy0"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv2LO_CrTAy0"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmJMXPtyTAy0"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9sQ-YmTAy0"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8MM012qTAy0"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDW8n_aaTAy0"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpwpIF89TAy0"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mb9JlA1TAy0"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyF6y6xITAy0",
        "outputId": "cc9e0af5-29f6-4f70-dfb6-bb1e3d069c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4142 - loss: 3053.1611 - val_accuracy: 0.2327 - val_loss: 2.1540\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2298 - loss: 2.4527 - val_accuracy: 0.2372 - val_loss: 2.2076\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.2401 - loss: 2.5447 - val_accuracy: 0.1949 - val_loss: 2.2433\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2078 - loss: 2.7563 - val_accuracy: 0.2226 - val_loss: 2.3827\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2176 - loss: 2.4212 - val_accuracy: 0.2216 - val_loss: 2.1850\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2159 - loss: 2.3821 - val_accuracy: 0.2269 - val_loss: 2.2142\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2299 - loss: 2.3408 - val_accuracy: 0.2198 - val_loss: 2.3319\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.2155 - loss: 2.3965 - val_accuracy: 0.2262 - val_loss: 2.1539\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.2250 - loss: 2.3221 - val_accuracy: 0.2776 - val_loss: 2.1494\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2407 - loss: 2.4288 - val_accuracy: 0.2503 - val_loss: 2.0829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc13f67ca10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2svPqiHfTAy1"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_m06twcTAy1",
        "outputId": "1645bd36-1e16-4ea0-fc3d-802d692d8252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8301 - loss: 0.8478 - val_accuracy: 0.9571 - val_loss: 0.1551\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9640 - loss: 0.1283 - val_accuracy: 0.9668 - val_loss: 0.1297\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9745 - loss: 0.0912 - val_accuracy: 0.9685 - val_loss: 0.1466\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.0772 - val_accuracy: 0.9686 - val_loss: 0.1626\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0687 - val_accuracy: 0.9649 - val_loss: 0.2103\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0614 - val_accuracy: 0.9704 - val_loss: 0.1943\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0514 - val_accuracy: 0.9719 - val_loss: 0.1957\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0443 - val_accuracy: 0.9714 - val_loss: 0.2214\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9901 - loss: 0.0403 - val_accuracy: 0.9738 - val_loss: 0.2178\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0386 - val_accuracy: 0.9713 - val_loss: 0.2400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc13f1c1e10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fm4FrQaTAy1"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B8GAj83TAy1"
      },
      "source": [
        "### Increasing model capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x20VNPDUTAy1"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2cYbRFdCTAy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad06056-ae24-4da8-ee60-2038f1a300bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 1.0636 - val_accuracy: 0.9055 - val_loss: 0.3619\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.3658 - val_accuracy: 0.9150 - val_loss: 0.3103\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.3251 - val_accuracy: 0.9200 - val_loss: 0.2929\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2957 - val_accuracy: 0.9196 - val_loss: 0.2849\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2942 - val_accuracy: 0.9247 - val_loss: 0.2782\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2791 - val_accuracy: 0.9224 - val_loss: 0.2777\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2822 - val_accuracy: 0.9254 - val_loss: 0.2722\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2672 - val_accuracy: 0.9268 - val_loss: 0.2716\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2716 - val_accuracy: 0.9278 - val_loss: 0.2693\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2690 - val_accuracy: 0.9275 - val_loss: 0.2682\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.2652 - val_accuracy: 0.9273 - val_loss: 0.2664\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2676 - val_accuracy: 0.9286 - val_loss: 0.2666\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2652 - val_accuracy: 0.9283 - val_loss: 0.2651\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.2633 - val_accuracy: 0.9274 - val_loss: 0.2653\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.2594 - val_accuracy: 0.9282 - val_loss: 0.2640\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2559 - val_accuracy: 0.9290 - val_loss: 0.2636\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2512 - val_accuracy: 0.9299 - val_loss: 0.2627\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2549 - val_accuracy: 0.9293 - val_loss: 0.2627\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.2579 - val_accuracy: 0.9301 - val_loss: 0.2616\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.2544 - val_accuracy: 0.9297 - val_loss: 0.2618\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eyFFR3unTAy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "7105936d-25c8-4da8-a532-c6435454a916"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7bc13ef21ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss_ori = history_small_model.history[\"val_loss\"]\n",
        "#val_loss_small = history_smaller_model.history[\"val_loss\"]\n",
        "#val_loss_large = history_large_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss_ori, \"b--\",\n",
        "         label=\"Validation loss(original)\")\n",
        "#plt.plot(epochs, val_loss_small, \"r--\",\n",
        "         #label=\"Validation loss(small)\")\n",
        "#plt.plot(epochs, val_loss_large, \"g--\",\n",
        "         #label=\"Validation loss(large)\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfPxUFZzTAy2"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPKwlngNTAy3"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtCJ39QJTAy3"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5_W_rHkTAy3"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8PV612QTAy3"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfoD9A-ETAy3"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YgJ5StpTAy3"
      },
      "source": [
        "#### Reducing the network's size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWnLpUQYTAy3"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tGmZjcP1TAy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d76b13-f45f-4b3f-a02f-6b78a48ae6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.6607 - loss: 0.6189 - val_accuracy: 0.8522 - val_loss: 0.4271\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8879 - loss: 0.3600 - val_accuracy: 0.8855 - val_loss: 0.3173\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9193 - loss: 0.2544 - val_accuracy: 0.8562 - val_loss: 0.3423\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9332 - loss: 0.2037 - val_accuracy: 0.8923 - val_loss: 0.2761\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9483 - loss: 0.1625 - val_accuracy: 0.8802 - val_loss: 0.2951\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9570 - loss: 0.1396 - val_accuracy: 0.8887 - val_loss: 0.2837\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9683 - loss: 0.1154 - val_accuracy: 0.8831 - val_loss: 0.3076\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9692 - loss: 0.1017 - val_accuracy: 0.8836 - val_loss: 0.3111\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9752 - loss: 0.0893 - val_accuracy: 0.8810 - val_loss: 0.3329\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9812 - loss: 0.0743 - val_accuracy: 0.8813 - val_loss: 0.3484\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9837 - loss: 0.0650 - val_accuracy: 0.8793 - val_loss: 0.3615\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9879 - loss: 0.0536 - val_accuracy: 0.8775 - val_loss: 0.3901\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9912 - loss: 0.0446 - val_accuracy: 0.8771 - val_loss: 0.4053\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9935 - loss: 0.0371 - val_accuracy: 0.8760 - val_loss: 0.4273\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9941 - loss: 0.0325 - val_accuracy: 0.8720 - val_loss: 0.4742\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9944 - loss: 0.0290 - val_accuracy: 0.8730 - val_loss: 0.4716\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0272 - val_accuracy: 0.8700 - val_loss: 0.5196\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9976 - loss: 0.0204 - val_accuracy: 0.8720 - val_loss: 0.5204\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9980 - loss: 0.0165 - val_accuracy: 0.8725 - val_loss: 0.5513\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0138 - val_accuracy: 0.8551 - val_loss: 0.6485\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrGfMKYOTAy3"
      },
      "source": [
        "**Version of the model with lower capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kH4GyfEaTAy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531ae42d-3c4c-43d7-bb20-f0782556d367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.6404 - loss: 0.6516 - val_accuracy: 0.8493 - val_loss: 0.5569\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8488 - loss: 0.5217 - val_accuracy: 0.8267 - val_loss: 0.4750\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8853 - loss: 0.4314 - val_accuracy: 0.8592 - val_loss: 0.4112\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9073 - loss: 0.3638 - val_accuracy: 0.8837 - val_loss: 0.3613\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9191 - loss: 0.3065 - val_accuracy: 0.8883 - val_loss: 0.3292\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9271 - loss: 0.2679 - val_accuracy: 0.8904 - val_loss: 0.3070\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9348 - loss: 0.2364 - val_accuracy: 0.8853 - val_loss: 0.2977\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9398 - loss: 0.2134 - val_accuracy: 0.8869 - val_loss: 0.2880\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9431 - loss: 0.1922 - val_accuracy: 0.8928 - val_loss: 0.2777\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9510 - loss: 0.1751 - val_accuracy: 0.8906 - val_loss: 0.2783\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9541 - loss: 0.1628 - val_accuracy: 0.8918 - val_loss: 0.2745\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9573 - loss: 0.1507 - val_accuracy: 0.8898 - val_loss: 0.2784\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9627 - loss: 0.1352 - val_accuracy: 0.8902 - val_loss: 0.2781\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9676 - loss: 0.1238 - val_accuracy: 0.8897 - val_loss: 0.2833\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9699 - loss: 0.1150 - val_accuracy: 0.8876 - val_loss: 0.2886\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9714 - loss: 0.1092 - val_accuracy: 0.8882 - val_loss: 0.2919\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9769 - loss: 0.0973 - val_accuracy: 0.8868 - val_loss: 0.2985\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9789 - loss: 0.0935 - val_accuracy: 0.8850 - val_loss: 0.3089\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.0876 - val_accuracy: 0.8849 - val_loss: 0.3117\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9817 - loss: 0.0810 - val_accuracy: 0.8837 - val_loss: 0.3226\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1KRiSQ1TAy4"
      },
      "source": [
        "**Version of the model with higher capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gpYcEWJQTAy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2853eb58-6432-496d-d172-01c3e41fc13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 358ms/step - accuracy: 0.6118 - loss: 0.6436 - val_accuracy: 0.8633 - val_loss: 0.3420\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 295ms/step - accuracy: 0.8459 - loss: 0.3589 - val_accuracy: 0.8600 - val_loss: 0.3240\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 352ms/step - accuracy: 0.9137 - loss: 0.2222 - val_accuracy: 0.8744 - val_loss: 0.2928\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 357ms/step - accuracy: 0.9351 - loss: 0.1767 - val_accuracy: 0.8892 - val_loss: 0.2796\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 304ms/step - accuracy: 0.9491 - loss: 0.1385 - val_accuracy: 0.8853 - val_loss: 0.2984\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 318ms/step - accuracy: 0.9692 - loss: 0.0896 - val_accuracy: 0.8611 - val_loss: 0.3290\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 327ms/step - accuracy: 0.9848 - loss: 0.0612 - val_accuracy: 0.8831 - val_loss: 0.3056\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 334ms/step - accuracy: 0.9939 - loss: 0.0330 - val_accuracy: 0.8774 - val_loss: 0.3195\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 402ms/step - accuracy: 0.9976 - loss: 0.0270 - val_accuracy: 0.8802 - val_loss: 0.4351\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 337ms/step - accuracy: 0.9930 - loss: 0.0368 - val_accuracy: 0.8822 - val_loss: 0.3725\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 329ms/step - accuracy: 0.9998 - loss: 0.0092 - val_accuracy: 0.8847 - val_loss: 0.4572\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 353ms/step - accuracy: 0.9999 - loss: 0.0033 - val_accuracy: 0.8599 - val_loss: 0.6084\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 315ms/step - accuracy: 0.9566 - loss: 0.1813 - val_accuracy: 0.8837 - val_loss: 0.4675\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8843 - val_loss: 0.5502\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 346ms/step - accuracy: 0.9988 - loss: 0.0073 - val_accuracy: 0.8762 - val_loss: 0.4424\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8805 - val_loss: 0.5081\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8811 - val_loss: 0.5849\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 7.1349e-04 - val_accuracy: 0.8824 - val_loss: 0.6314\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.9942 - loss: 0.0329 - val_accuracy: 0.8804 - val_loss: 0.4986\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8821 - val_loss: 0.5382\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_larger_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRfgQw1pTAy4"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjShH_tYTAy4"
      },
      "source": [
        "**Adding L2 weight regularization to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y975VcwlTAy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005caf1a-5083-4cd3-8d17-0517aacd6138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6819 - loss: 0.7060 - val_accuracy: 0.8359 - val_loss: 0.5126\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8801 - loss: 0.4553 - val_accuracy: 0.8820 - val_loss: 0.4065\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9155 - loss: 0.3515 - val_accuracy: 0.8864 - val_loss: 0.3716\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9259 - loss: 0.2993 - val_accuracy: 0.8865 - val_loss: 0.3552\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9362 - loss: 0.2731 - val_accuracy: 0.8831 - val_loss: 0.3562\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9446 - loss: 0.2522 - val_accuracy: 0.8847 - val_loss: 0.3568\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9520 - loss: 0.2318 - val_accuracy: 0.8860 - val_loss: 0.3521\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9548 - loss: 0.2249 - val_accuracy: 0.8867 - val_loss: 0.3561\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9563 - loss: 0.2191 - val_accuracy: 0.8825 - val_loss: 0.3674\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9601 - loss: 0.2082 - val_accuracy: 0.8827 - val_loss: 0.3671\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9623 - loss: 0.2002 - val_accuracy: 0.8820 - val_loss: 0.3742\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9651 - loss: 0.1979 - val_accuracy: 0.8797 - val_loss: 0.3775\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9679 - loss: 0.1896 - val_accuracy: 0.8785 - val_loss: 0.3864\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9636 - loss: 0.1909 - val_accuracy: 0.8784 - val_loss: 0.3859\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9673 - loss: 0.1870 - val_accuracy: 0.8794 - val_loss: 0.3896\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9699 - loss: 0.1810 - val_accuracy: 0.8774 - val_loss: 0.3964\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9737 - loss: 0.1774 - val_accuracy: 0.8785 - val_loss: 0.3983\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9709 - loss: 0.1797 - val_accuracy: 0.8728 - val_loss: 0.4180\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9714 - loss: 0.1756 - val_accuracy: 0.8760 - val_loss: 0.4080\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9755 - loss: 0.1700 - val_accuracy: 0.8647 - val_loss: 0.4565\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fESbLJHeTAy4"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sOspX25jTAy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab996139-d9aa-48e6-bc12-31539253402a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.regularizers.regularizers.L1L2 at 0x7bc0909a7bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnVpBnSWTAy4"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7c2jC3TAy4"
      },
      "source": [
        "**Adding dropout to the IMDB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dExWim8ZTAy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa44818-bccf-4d43-e145-2783c737cc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.5898 - loss: 0.6671 - val_accuracy: 0.8432 - val_loss: 0.5103\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7647 - loss: 0.5223 - val_accuracy: 0.8722 - val_loss: 0.4055\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8249 - loss: 0.4302 - val_accuracy: 0.8835 - val_loss: 0.3278\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8677 - loss: 0.3563 - val_accuracy: 0.8891 - val_loss: 0.2956\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8948 - loss: 0.3082 - val_accuracy: 0.8832 - val_loss: 0.2841\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9089 - loss: 0.2644 - val_accuracy: 0.8894 - val_loss: 0.2795\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9205 - loss: 0.2373 - val_accuracy: 0.8837 - val_loss: 0.2858\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9331 - loss: 0.2050 - val_accuracy: 0.8913 - val_loss: 0.2840\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9394 - loss: 0.1870 - val_accuracy: 0.8866 - val_loss: 0.3033\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9436 - loss: 0.1705 - val_accuracy: 0.8887 - val_loss: 0.3101\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9567 - loss: 0.1404 - val_accuracy: 0.8812 - val_loss: 0.3537\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9561 - loss: 0.1336 - val_accuracy: 0.8868 - val_loss: 0.3564\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9598 - loss: 0.1229 - val_accuracy: 0.8867 - val_loss: 0.3812\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9689 - loss: 0.1045 - val_accuracy: 0.8880 - val_loss: 0.3913\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9684 - loss: 0.0978 - val_accuracy: 0.8819 - val_loss: 0.4267\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9692 - loss: 0.0976 - val_accuracy: 0.8846 - val_loss: 0.4266\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9732 - loss: 0.0897 - val_accuracy: 0.8855 - val_loss: 0.4678\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9726 - loss: 0.0840 - val_accuracy: 0.8830 - val_loss: 0.5124\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9762 - loss: 0.0737 - val_accuracy: 0.8822 - val_loss: 0.4987\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9819 - loss: 0.0624 - val_accuracy: 0.8837 - val_loss: 0.5480\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpNwJE0bTAy4"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}